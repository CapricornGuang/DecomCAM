# Decom-CAM: Feature-Level Interpretation via Decomposition Class Activation Map
![Python 3.6.5](https://img.shields.io/badge/python-3.6.5-green.svg?style=plastic)
![PyTorch 1.2](https://img.shields.io/badge/PyTorch-1.12.0-orange?style=plastic)
![License CC BY-NC-SA](https://img.shields.io/badge/license-CC_BY--NC--SA--green.svg?style=plastic)


This is the origin Pytorch implementation of Diviner in the following paper: 
[Decom-CAM: Tell Me What You See, In Details! Feature-Level Interpretation via Decomposition Class Activation Map](???).


## Decom-CAM Framework
This paper proposes a new two-stage interpretability method called the Decomposition Class Activation Map (Decom-CAM), which offers a feature-level interpretation of the model's prediction. Decom-CAM decomposes intermediate activation maps into orthogonal features using singular value decomposition and generates saliency maps by integrating them. The orthogonality of features enables CAM to capture local features and can be used to pinpoint semantic components such as eyes, noses, and faces in the input image, making it more beneficial for deep model interpretation.

<p align="center">
<img src=".\.img/Framework_00.png" height = "480" alt="" align=center />
<br><br>
<b>Figure 1.</b> The illustration of Decom-CAM's decomposition stage.
</p>

## New protocol on Deletion and Insertion Metric
This paper proposes a new protocol based on the deletion-insertion test to solve these limitations. This protocol involves: 1) dividing the test set into multiple subsets based on the model's performance, using a benchmark accuracy of 10\% as the interval criterion for subset creation, which results in 10 distinct subsets that can be evaluated separately to assess the interpretability performance of each saliency method and we can investigate the interpretability performance under distinct model's prediction performance; 2) excluding the instances that the underlying model makes incorrect predictions. This protocol promises that we can obtain a comprehensive assessment of different CAM methods in a rigorous and appropriate manner.

<p align="center">
<img src=".\.img/metric_00.png" height = "300" alt="" align=center />
<br><br>
<b>Figure 2.</b> The Insertion-Deletion test under the proposed new protocal.
</p>

## Reproducibility
We provide various class activation map methods implementing from the source code.
The tree below illustrates the organization of this project.
```bash
├── src
│   ├── checkpoints # folder to store pretrained models
│   ├── cam # the implement of various CAM methods
│   │   ├──basecam.py # the prototype (or templete) for all cam implement
│   │   ├──grad-cam.py # an important father class for gradient-based cams
│   │   ├──...
│   ├── utils
│   │   ├──api.py #define an api function supports calling different CAM methods.
│   │   ├──translate_tools.py #tools
│   │   ├──viz_tools.py #Visualization tools
├── ins_del_gc.py #the automatic evaluating metric of Insertion & Deletion, reference:https://github.com/wofmanaf/Group-CAM
├── main.py
```

## Results
<p align="center">
<img src=".\.img/saliency_00.png" height = "600" alt="" align=center />
<br><br>
<b>Figure 3.</b> Visualization comparisons of Decom-CAM and currently popular CAM-based saliency map methods.
</p>
<p align="center">
<img src=".\.img/local_00.png" height = "400" alt="" align=center />
<br><br>
<b>Figure 4.</b> Visualization of the local saliency maps with different backbones.
</p>

